{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nid_op = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\n\nnode_ops = [[]]*10\nnode_ops[0] = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nnode_ops[1] = ['none']\nnode_ops[2] = ['nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nnode_ops[3] = ['nor_conv_1x1','nor_conv_3x3']\nnode_ops[4] = ['skip_connect','avg_pool_3x3']\nnode_ops[5] = ['nor_conv_1x1']\nnode_ops[6] = ['nor_conv_3x3']\nnode_ops[7] = ['skip_connect']\nnode_ops[8] = ['avg_pool_3x3']\n\nL = [(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)]\n\n'''\nReferences: NATS-Bench source code (on topology search space (tss)): \nhttps://github.com/D-X-Y/AutoDL-Projects/tree/f46486e21b71ae6459a700be720d7648b5429569/xautodl\n\nThe following classes are modified compared to original version: MixedOp, Cell\n\nArch (seems to) play the role of Gentotypes in the original implementation\nCell (seems to) play the role of InferCell in the original implementation\n'''\n\nOPS = {\n    \"none\": lambda C_in, C_out, stride, affine, track_running_stats: Zero(\n        C_in, C_out, stride\n    ),\n    \"avg_pool_3x3\": lambda C_in, C_out, stride, affine, track_running_stats: POOLING(\n        C_in, C_out, stride, \"avg\", affine, track_running_stats\n    ),\n    \"nor_conv_3x3\": lambda C_in, C_out, stride, affine, track_running_stats: ReLUConvBN(\n        C_in,\n        C_out,\n        (3, 3),\n        (stride, stride),\n        (1, 1),\n        (1, 1),\n        affine,\n        track_running_stats,\n    ),\n    \"nor_conv_1x1\": lambda C_in, C_out, stride, affine, track_running_stats: ReLUConvBN(\n        C_in,\n        C_out,\n        (1, 1),\n        (stride, stride),\n        (0, 0),\n        (1, 1),\n        affine,\n        track_running_stats,\n    ),\n    \"skip_connect\": lambda C_in, C_out, stride, affine, track_running_stats: Identity()\n    if stride == 1 and C_in == C_out\n    else FactorizedReduce(C_in, C_out, stride, affine, track_running_stats),\n}\n\nclass ReLUConvBN(nn.Module):\n    def __init__(\n        self,\n        C_in,\n        C_out,\n        kernel_size,\n        stride,\n        padding,\n        dilation,\n        affine,\n        track_running_stats=True,\n    ):\n        super(ReLUConvBN, self).__init__()\n        self.op = nn.Sequential(\n            nn.ReLU(inplace=False),\n            nn.Conv2d(\n                C_in,\n                C_out,\n                kernel_size,\n                stride=stride,\n                padding=padding,\n                dilation=dilation,\n                bias=not affine,\n            ),\n            nn.BatchNorm2d(\n                C_out, affine=affine, track_running_stats=track_running_stats\n            ),\n        )\n\n    def forward(self, x):\n        return self.op(x)\n\nclass POOLING(nn.Module):\n    def __init__(\n        self, C_in, C_out, stride, mode, affine=True, track_running_stats=True\n    ):\n        super(POOLING, self).__init__()\n        if C_in == C_out:\n            self.preprocess = None\n        else:\n            self.preprocess = ReLUConvBN(\n                C_in, C_out, 1, 1, 0, 1, affine, track_running_stats\n            )\n        if mode == \"avg\":\n            self.op = nn.AvgPool2d(3, stride=stride, padding=1, count_include_pad=False)\n        elif mode == \"max\":\n            self.op = nn.MaxPool2d(3, stride=stride, padding=1)\n        else:\n            raise ValueError(\"Invalid mode={:} in POOLING\".format(mode))\n\n    def forward(self, inputs):\n        if self.preprocess:\n            x = self.preprocess(inputs)\n        else:\n            x = inputs\n        return self.op(x)\n\nclass Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n\n    def forward(self, x):\n        return x\n\nclass Zero(nn.Module):\n    def __init__(self, C_in, C_out, stride):\n        super(Zero, self).__init__()\n        self.C_in = C_in\n        self.C_out = C_out\n        self.stride = stride\n        self.is_zero = True\n\n    def forward(self, x):\n        if self.C_in == self.C_out:\n            if self.stride == 1:\n                return x.mul(0.0)\n            else:\n                return x[:, :, :: self.stride, :: self.stride].mul(0.0)\n        else:\n            shape = list(x.shape)\n            shape[1] = self.C_out\n            zeros = x.new_zeros(shape, dtype=x.dtype, device=x.device)\n            return zeros\n\n    def extra_repr(self):\n        return \"C_in={C_in}, C_out={C_out}, stride={stride}\".format(**self.__dict__)\n\nclass FactorizedReduce(nn.Module):\n    def __init__(self, C_in, C_out, stride, affine, track_running_stats):\n        super(FactorizedReduce, self).__init__()\n        self.stride = stride\n        self.C_in = C_in\n        self.C_out = C_out\n        self.relu = nn.ReLU(inplace=False)\n        if stride == 2:\n            # assert C_out % 2 == 0, 'C_out : {:}'.format(C_out)\n            C_outs = [C_out // 2, C_out - C_out // 2]\n            self.convs = nn.ModuleList()\n            for i in range(2):\n                self.convs.append(\n                    nn.Conv2d(\n                        C_in, C_outs[i], 1, stride=stride, padding=0, bias=not affine\n                    )\n                )\n            self.pad = nn.ConstantPad2d((0, 1, 0, 1), 0)\n        elif stride == 1:\n            self.conv = nn.Conv2d(\n                C_in, C_out, 1, stride=stride, padding=0, bias=not affine\n            )\n        else:\n            raise ValueError(\"Invalid stride : {:}\".format(stride))\n        self.bn = nn.BatchNorm2d(\n            C_out, affine=affine, track_running_stats=track_running_stats\n        )\n\n    def forward(self, x):\n        if self.stride == 2:\n            x = self.relu(x)\n            y = self.pad(x)\n            out = torch.cat([self.convs[0](x), self.convs[1](y[:, :, 1:, 1:])], dim=1)\n        else:\n            out = self.conv(x)\n        out = self.bn(out)\n        return out\n\n    def extra_repr(self):\n        return \"C_in={C_in}, C_out={C_out}, stride={stride}\".format(**self.__dict__)\n\nclass MixedOp(nn.Module):\n    def __init__(self, ops, C_in, C_out, stride=1, affine= True, track_running_stats= True):\n        super(MixedOp, self).__init__()\n        self.C_in = C_in\n        self.C_out = C_out\n        self.affine = affine\n        self.track_running_stats = track_running_stats\n        self.stride = stride\n        self.ops = nn.ModuleList()\n        for op in ops:\n            cuda_op = OPS[op](C_in, C_out, stride, affine, track_running_stats)\n            self.ops.append(cuda_op)\n\n    def forward(self, x):\n        rx = torch.zeros_like(x)\n        for st_op in self.ops:\n            rx = rx + st_op(x)\n        return rx\n\nclass Cell(nn.Module):\n    def __init__(self, Arch, C_in, C_out, stride, affine= True, track_running_stats= True):\n        super(Cell, self).__init__()\n        self.Arch = Arch\n        self.C_in = C_in\n        self.C_out = C_out\n        self.affine = affine\n        self.track_running_stats = track_running_stats\n        self.stride = stride\n        self.out_dim = C_out\n        self.ops = nn.ModuleList()\n        for i in range(6):\n            ops = node_ops[self.Arch[i]]\n            st_op = MixedOp(ops, C_in, C_out)\n            self.ops.append(st_op)\n\n    def forward(self, x):\n        layers = [torch.zeros_like(x)]*6\n        layers[0] = x\n        for i in range(6):\n            s, t = L[i]\n            st_op = self.ops[i]\n            layers[t] = layers[t] + st_op(layers[s])\n        return layers[3]\n\nclass ResNetBasicblock(nn.Module):\n    def __init__(self, inplanes, planes, stride, affine=True, track_running_stats=True):\n        super(ResNetBasicblock, self).__init__()\n        assert stride == 1 or stride == 2, \"invalid stride {:}\".format(stride)\n        self.conv_a = ReLUConvBN(\n            inplanes, planes, 3, stride, 1, 1, affine, track_running_stats\n        )\n        self.conv_b = ReLUConvBN(\n            planes, planes, 3, 1, 1, 1, affine, track_running_stats\n        )\n        if stride == 2:\n            self.downsample = nn.Sequential(\n                nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n                nn.Conv2d(\n                    inplanes, planes, kernel_size=1, stride=1, padding=0, bias=False\n                ),\n            )\n        elif inplanes != planes:\n            self.downsample = ReLUConvBN(\n                inplanes, planes, 1, 1, 0, 1, affine, track_running_stats\n            )\n        else:\n            self.downsample = None\n        self.in_dim = inplanes\n        self.out_dim = planes\n        self.stride = stride\n        self.num_conv = 2\n\n    def extra_repr(self):\n        string = \"{name}(inC={in_dim}, outC={out_dim}, stride={stride})\".format(\n            name=self.__class__.__name__, **self.__dict__\n        )\n        return string\n\n    def forward(self, inputs):\n\n        basicblock = self.conv_a(inputs)\n        basicblock = self.conv_b(basicblock)\n\n        if self.downsample is not None:\n            residual = self.downsample(inputs)\n        else:\n            residual = inputs\n        return residual + basicblock\n\nclass TinyNetwork(nn.Module):\n    def __init__(self, C, N, Arch, num_classes):\n        '''\n        Initial Macro parameters (according to NAS-Bench-201):\n        C: Input channel of 1st stack: 16\n        N: Number of DAG-Cell/stack: 5\n        num_classes: =10 on CIFAR-10 (probably?)\n        '''\n        super(TinyNetwork, self).__init__()\n        self._C = C\n        self._layerN = N\n        self.Arch = Arch\n        self.num_classes = num_classes\n\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(C)\n        )\n\n        layer_channels = [C] * N + [C * 2] + [C * 2] * N + [C * 4] + [C * 4] * N\n        layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n        C_prev = C\n        self.cells = nn.ModuleList()\n        for index, (C_curr, reduction) in enumerate(\n            zip(layer_channels, layer_reductions)\n        ):\n            if reduction:\n                cell = ResNetBasicblock(C_prev, C_curr, 2, True)\n            else:\n                cell = Cell(Arch, C_prev, C_curr, 1)\n            self.cells.append(cell)\n            C_prev = cell.out_dim\n        self._Layer = len(self.cells)\n\n        self.lastact = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n        self.global_pooling = nn.AdaptiveAvgPool2d(1)\n        self.classifier = nn.Linear(C_prev, num_classes)\n\n    def get_message(self):\n        string = self.extra_repr()\n        for i, cell in enumerate(self.cells):\n            string += \"\\n {:02d}/{:02d} :: {:}\".format(\n                i, len(self.cells), cell.extra_repr()\n            )\n        return string\n\n    def extra_repr(self):\n        return \"{name}(C={_C}, N={_layerN}, L={_Layer})\".format(\n            name=self.__class__.__name__, **self.__dict__\n        )\n\n    def forward(self, inputs):\n        feature = self.stem(inputs)\n        for i, cell in enumerate(self.cells):\n            feature = cell(feature)\n\n        out = self.lastact(feature)\n        out = self.global_pooling(out)\n        out = out.view(out.size(0), -1)\n        logits = self.classifier(out)\n\n        return out","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-31T05:39:58.510159Z","iopub.execute_input":"2022-12-31T05:39:58.510868Z","iopub.status.idle":"2022-12-31T05:40:00.226172Z","shell.execute_reply.started":"2022-12-31T05:39:58.510777Z","shell.execute_reply":"2022-12-31T05:40:00.225196Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torch.nn.functional as F\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nnum_epochs = 2\nbatch_size = 256\n\ntrainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n                                        download=True, transform=transform)\ntrain_indices = range(25000)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=False,sampler=train_indices)\n#tao sẽ thêm phần validation sau\n\nval_indices = range(25000,50000)\nvalloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=False,sampler=val_indices)\n\nfinal_indices = range(50000)\nfinalloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=False,sampler=final_indices)\n\ntestset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\ndef get_metric(Arch, final= False):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    net = TinyNetwork(16,5,Arch,10)\n    net.to(device)\n    criterion  = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9,nesterov=True,weight_decay=0.0005)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max = 200,eta_min=0)\n\n    global num_epochs\n    \n    if final:\n        num_epochs = 12\n    else:\n        num_epochs = 2\n    \n    for epoch in range(num_epochs):\n        net.train()\n        scheduler.step()\n        loader = trainloader\n        if final:\n            loader = finalloader\n        for inputs, labels in loader:\n            inputs,labels = inputs.to(device),labels.to(device)\n            # get the inputs; data is a list of [inputs, labels]\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs.float())\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        \n    with torch.no_grad():\n        correct = 0\n        total = 0\n        net.eval()\n        loader = valloader\n        if final:\n            loader = testloader\n        for inputs, labels in loader: #về sau ở đây t sẽ thay bằng validation\n            inputs,labels = inputs.to(device),labels.to(device)\n            outputs = net(inputs.float())\n            loss = criterion(outputs,labels)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.cpu().detach().size(0)\n            correct += (predicted == labels).sum().item()\n\n        acc = float(correct/total)\n        if final:\n            print('Final Judge:')\n        print(f'Accuracy of the network on the 10000 test images: {100 * acc} %')\n    return acc","metadata":{"execution":{"iopub.status.busy":"2022-12-31T05:40:00.230191Z","iopub.execute_input":"2022-12-31T05:40:00.230602Z","iopub.status.idle":"2022-12-31T05:40:07.593585Z","shell.execute_reply.started":"2022-12-31T05:40:00.230575Z","shell.execute_reply":"2022-12-31T05:40:07.592600Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170498071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30a7780e15ab45dc9604579aa8766366"}},"metadata":{}},{"name":"stdout","text":"Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport time\n# from nas_201_api import NASBench201API as API\n\n# Operation tree design\nnode_ops = [[]]*9 # operations on id-th node\ne = [[]]*9 # edge list\npar = [-1]*9 # parent list\n\ne[0] = [1,2]\ne[2] = [3,4]\ne[3] = [5,6]\ne[4] = [7,8]\n\npar[1] = 0\npar[2] = 0\npar[3] = 2\npar[4] = 2\npar[5] = 3\npar[6] = 3\npar[7] = 4\npar[8] = 4\n\n\nnode_ops[0] = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nnode_ops[1] = ['none']\nnode_ops[2] = ['nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nnode_ops[3] = ['nor_conv_1x1','nor_conv_3x3']\nnode_ops[4] = ['skip_connect','avg_pool_3x3']\nnode_ops[5] = ['nor_conv_1x1']\nnode_ops[6] = ['nor_conv_3x3']\nnode_ops[7] = ['skip_connect']\nnode_ops[8] = ['avg_pool_3x3']\n\n# Cell's DAG edge list\nL = [(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)]\n\n# Encoding candidates and operations\nid_op = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nmasks = []\n\ndef To_mask(num):\n    res = ''\n    while(num > 0):\n        res += str(num % 2)\n        num = int(num/2)\n    while(len(res) < 6):\n        res += '0'\n    res = res[::-1]\n    return res\n\ndef Build_masks():\n    mask_len = 2**6 - 1\n    for i in range(mask_len + 1):\n        masks.append(To_mask(i))\n    print(\"Build_masks: Done\")\n\ndef Build_cand_arch(Arch, mask):\n    Cand_arch = []\n    Len = len(mask)\n    for i in range(Len):\n        if len(e[Arch[i]]) < 2:\n            Cand_arch.append(Arch[i])\n            continue\n        o0 = e[Arch[i]][0]\n        o1 = e[Arch[i]][1]\n        b = mask[i]\n        op = o0\n        if b == '1':\n            op = o1\n        Cand_arch.append(op)\n    return Cand_arch\n\ndef Score(Arch, final= False):\n    return get_metric(Arch, final)\n\ndef Check_connected(Arch):\n    '''\n    if (Arch[0] == 1) and (Arch[1] == 1) and (Arch[2] == 1):\n        return False\n    if (Arch[4] == 1) and (Arch[5] == 1):\n        return False\n    '''\n    fr = [True]*4\n    fr[0] = False\n    for i in range(6):\n        s, t = L[i]\n        if Arch[i] == 1:\n            continue\n        fr[t] = (fr[s] and fr[t])\n    return not fr[3]\n\ndef BFS_T_o():\n    Arch = [0,0,0,0,0,0]\n    q = []\n    q.insert(0,0) # queue.push()\n    for i in range(3):\n        Cur_arch = Build_cand_arch(Arch, To_mask(0))\n        print(i, Cur_arch)\n        score = Score(Cur_arch)\n        for mask in masks:\n            Cand_arch = Build_cand_arch(Arch, mask)\n            print(mask, Cand_arch, Check_connected(Cand_arch))\n            if not Check_connected(Cand_arch):\n                continue\n            if Cur_arch == Cand_arch: \n                continue\n            cand_score = Score(Cand_arch)\n            if score < cand_score:\n                Cur_arch = Cand_arch\n                score = cand_score\n        Arch = Cur_arch\n    print(Arch)\n    final_score = Score(Arch, final= True)\n\nBuild_masks()\nBFS_T_o()","metadata":{"execution":{"iopub.status.busy":"2022-12-31T05:40:07.595220Z","iopub.execute_input":"2022-12-31T05:40:07.595804Z","iopub.status.idle":"2022-12-31T07:38:44.122546Z","shell.execute_reply.started":"2022-12-31T05:40:07.595763Z","shell.execute_reply":"2022-12-31T07:38:44.120768Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Build_masks: Done\n0 [1, 1, 1, 1, 1, 1]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 10.036000000000001 %\n000000 [1, 1, 1, 1, 1, 1] False\n000001 [1, 1, 1, 1, 1, 2] False\n000010 [1, 1, 1, 1, 2, 1] False\n000011 [1, 1, 1, 1, 2, 2] False\n000100 [1, 1, 1, 2, 1, 1] False\n000101 [1, 1, 1, 2, 1, 2] False\n000110 [1, 1, 1, 2, 2, 1] False\n000111 [1, 1, 1, 2, 2, 2] False\n001000 [1, 1, 2, 1, 1, 1] True\nAccuracy of the network on the 10000 test images: 41.112 %\n001001 [1, 1, 2, 1, 1, 2] True\nAccuracy of the network on the 10000 test images: 40.036 %\n001010 [1, 1, 2, 1, 2, 1] True\nAccuracy of the network on the 10000 test images: 35.82 %\n001011 [1, 1, 2, 1, 2, 2] True\nAccuracy of the network on the 10000 test images: 39.519999999999996 %\n001100 [1, 1, 2, 2, 1, 1] True\nAccuracy of the network on the 10000 test images: 37.36 %\n001101 [1, 1, 2, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 24.788 %\n001110 [1, 1, 2, 2, 2, 1] True\nAccuracy of the network on the 10000 test images: 34.652 %\n001111 [1, 1, 2, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 17.532 %\n010000 [1, 2, 1, 1, 1, 1] False\n010001 [1, 2, 1, 1, 1, 2] True\nAccuracy of the network on the 10000 test images: 35.544 %\n010010 [1, 2, 1, 1, 2, 1] False\n010011 [1, 2, 1, 1, 2, 2] True\nAccuracy of the network on the 10000 test images: 40.788000000000004 %\n010100 [1, 2, 1, 2, 1, 1] False\n010101 [1, 2, 1, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 41.024 %\n010110 [1, 2, 1, 2, 2, 1] False\n010111 [1, 2, 1, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 39.832 %\n011000 [1, 2, 2, 1, 1, 1] True\nAccuracy of the network on the 10000 test images: 40.792 %\n011001 [1, 2, 2, 1, 1, 2] True\nAccuracy of the network on the 10000 test images: 36.052 %\n011010 [1, 2, 2, 1, 2, 1] True\nAccuracy of the network on the 10000 test images: 42.903999999999996 %\n011011 [1, 2, 2, 1, 2, 2] True\nAccuracy of the network on the 10000 test images: 33.852 %\n011100 [1, 2, 2, 2, 1, 1] True\nAccuracy of the network on the 10000 test images: 39.275999999999996 %\n011101 [1, 2, 2, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 39.612 %\n011110 [1, 2, 2, 2, 2, 1] True\nAccuracy of the network on the 10000 test images: 37.891999999999996 %\n011111 [1, 2, 2, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 37.656 %\n100000 [2, 1, 1, 1, 1, 1] False\n100001 [2, 1, 1, 1, 1, 2] False\n100010 [2, 1, 1, 1, 2, 1] True\nAccuracy of the network on the 10000 test images: 40.436 %\n100011 [2, 1, 1, 1, 2, 2] True\nAccuracy of the network on the 10000 test images: 39.804 %\n100100 [2, 1, 1, 2, 1, 1] False\n100101 [2, 1, 1, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 38.14 %\n100110 [2, 1, 1, 2, 2, 1] True\nAccuracy of the network on the 10000 test images: 38.519999999999996 %\n100111 [2, 1, 1, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 39.739999999999995 %\n101000 [2, 1, 2, 1, 1, 1] True\nAccuracy of the network on the 10000 test images: 40.208 %\n101001 [2, 1, 2, 1, 1, 2] True\nAccuracy of the network on the 10000 test images: 43.348 %\n101010 [2, 1, 2, 1, 2, 1] True\nAccuracy of the network on the 10000 test images: 40.083999999999996 %\n101011 [2, 1, 2, 1, 2, 2] True\nAccuracy of the network on the 10000 test images: 38.412 %\n101100 [2, 1, 2, 2, 1, 1] True\nAccuracy of the network on the 10000 test images: 38.64 %\n101101 [2, 1, 2, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 40.104 %\n101110 [2, 1, 2, 2, 2, 1] True\nAccuracy of the network on the 10000 test images: 43.016 %\n101111 [2, 1, 2, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 10.084 %\n110000 [2, 2, 1, 1, 1, 1] False\n110001 [2, 2, 1, 1, 1, 2] True\nAccuracy of the network on the 10000 test images: 37.416 %\n110010 [2, 2, 1, 1, 2, 1] True\nAccuracy of the network on the 10000 test images: 38.216 %\n110011 [2, 2, 1, 1, 2, 2] True\nAccuracy of the network on the 10000 test images: 34.86 %\n110100 [2, 2, 1, 2, 1, 1] False\n110101 [2, 2, 1, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 35.088 %\n110110 [2, 2, 1, 2, 2, 1] True\nAccuracy of the network on the 10000 test images: 32.856 %\n110111 [2, 2, 1, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 9.852 %\n111000 [2, 2, 2, 1, 1, 1] True\nAccuracy of the network on the 10000 test images: 39.324 %\n111001 [2, 2, 2, 1, 1, 2] True\nAccuracy of the network on the 10000 test images: 39.964 %\n111010 [2, 2, 2, 1, 2, 1] True\nAccuracy of the network on the 10000 test images: 35.96 %\n111011 [2, 2, 2, 1, 2, 2] True\nAccuracy of the network on the 10000 test images: 36.815999999999995 %\n111100 [2, 2, 2, 2, 1, 1] True\nAccuracy of the network on the 10000 test images: 41.004000000000005 %\n111101 [2, 2, 2, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 15.415999999999999 %\n111110 [2, 2, 2, 2, 2, 1] True\nAccuracy of the network on the 10000 test images: 32.572 %\n111111 [2, 2, 2, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 10.036000000000001 %\n1 [3, 1, 3, 1, 1, 3]\nAccuracy of the network on the 10000 test images: 46.004 %\n000000 [3, 1, 3, 1, 1, 3] True\n000001 [3, 1, 3, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 44.832 %\n000010 [3, 1, 3, 1, 1, 3] True\n000011 [3, 1, 3, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 45.432 %\n000100 [3, 1, 3, 1, 1, 3] True\n000101 [3, 1, 3, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 50.308 %\n000110 [3, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 39.076 %\n000111 [3, 1, 3, 1, 1, 4] True\n001000 [3, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 25.428 %\n001001 [3, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 29.176000000000002 %\n001010 [3, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 27.612 %\n001011 [3, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 25.652 %\n001100 [3, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 24.524 %\n001101 [3, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 31.052000000000003 %\n001110 [3, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 32.432 %\n001111 [3, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 21.208 %\n010000 [3, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 30.84 %\n010001 [3, 1, 3, 1, 1, 4] True\n010010 [3, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 45.516 %\n010011 [3, 1, 3, 1, 1, 4] True\n010100 [3, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 47.496 %\n010101 [3, 1, 3, 1, 1, 4] True\n010110 [3, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 51.144 %\n010111 [3, 1, 3, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 49.552 %\n011000 [3, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 27.564 %\n011001 [3, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 28.096 %\n011010 [3, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 26.667999999999996 %\n011011 [3, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 26.484 %\n011100 [3, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 11.728 %\n011101 [3, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 28.871999999999996 %\n011110 [3, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 21.560000000000002 %\n011111 [3, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 25.284000000000002 %\n100000 [4, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 35.839999999999996 %\n100001 [4, 1, 3, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 47.699999999999996 %\n100010 [4, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 47.048 %\n100011 [4, 1, 3, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 55.535999999999994 %\n100100 [4, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 49.647999999999996 %\n100101 [4, 1, 3, 1, 1, 4] True\n100110 [4, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 49.864000000000004 %\n100111 [4, 1, 3, 1, 1, 4] True\n101000 [4, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 29.720000000000002 %\n101001 [4, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 24.736 %\n101010 [4, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 26.304 %\n101011 [4, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 28.727999999999998 %\n101100 [4, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 28.496 %\n101101 [4, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 19.032 %\n101110 [4, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 27.232 %\n101111 [4, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 26.740000000000002 %\n110000 [4, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 50.104000000000006 %\n110001 [4, 1, 3, 1, 1, 4] True\n110010 [4, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 52.284 %\n110011 [4, 1, 3, 1, 1, 4] True\n110100 [4, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 51.664 %\n110101 [4, 1, 3, 1, 1, 4] True\n110110 [4, 1, 3, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 36.336 %\n110111 [4, 1, 3, 1, 1, 4] True\n111000 [4, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 30.636000000000003 %\n111001 [4, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 26.016000000000002 %\n111010 [4, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 28.671999999999997 %\n111011 [4, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 24.86 %\n111100 [4, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 17.46 %\n111101 [4, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 26.0 %\n111110 [4, 1, 4, 1, 1, 3] True\nAccuracy of the network on the 10000 test images: 24.468 %\n111111 [4, 1, 4, 1, 1, 4] True\nAccuracy of the network on the 10000 test images: 31.276 %\n2 [7, 1, 5, 1, 1, 7]\nAccuracy of the network on the 10000 test images: 47.736000000000004 %\n000000 [7, 1, 5, 1, 1, 7] True\n000001 [7, 1, 5, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 50.44 %\n000010 [7, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 49.24 %\n000011 [7, 1, 5, 1, 1, 8] True\n000100 [7, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 45.379999999999995 %\n000101 [7, 1, 5, 1, 1, 8] True\n000110 [7, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 37.324 %\n000111 [7, 1, 5, 1, 1, 8] True\n001000 [7, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 41.524 %\n001001 [7, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 36.36 %\n001010 [7, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 39.160000000000004 %\n001011 [7, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 37.456 %\n001100 [7, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 44.024 %\n001101 [7, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 34.872 %\n001110 [7, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 39.296 %\n001111 [7, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 41.22 %\n010000 [7, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 44.832 %\n010001 [7, 1, 5, 1, 1, 8] True\n010010 [7, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 44.784 %\n010011 [7, 1, 5, 1, 1, 8] True\n010100 [7, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 36.656 %\n010101 [7, 1, 5, 1, 1, 8] True\n010110 [7, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 31.86 %\n010111 [7, 1, 5, 1, 1, 8] True\n011000 [7, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 43.812 %\n011001 [7, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 42.344 %\n011010 [7, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 46.123999999999995 %\n011011 [7, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 39.983999999999995 %\n011100 [7, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 43.692 %\n011101 [7, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 44.184 %\n011110 [7, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 40.032000000000004 %\n011111 [7, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 39.376 %\n100000 [8, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 44.816 %\n100001 [8, 1, 5, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 40.94 %\n100010 [8, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 47.996 %\n100011 [8, 1, 5, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 46.836 %\n100100 [8, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 41.752 %\n100101 [8, 1, 5, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 40.160000000000004 %\n100110 [8, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 43.424 %\n100111 [8, 1, 5, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 50.983999999999995 %\n101000 [8, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 30.620000000000005 %\n101001 [8, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 37.484 %\n101010 [8, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 41.988 %\n101011 [8, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 43.196 %\n101100 [8, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 46.94 %\n101101 [8, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 38.82 %\n101110 [8, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 39.212 %\n101111 [8, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 43.22 %\n110000 [8, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 45.848 %\n110001 [8, 1, 5, 1, 1, 8] True\n110010 [8, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 41.628 %\n110011 [8, 1, 5, 1, 1, 8] True\n110100 [8, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 39.224 %\n110101 [8, 1, 5, 1, 1, 8] True\n110110 [8, 1, 5, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 46.892 %\n110111 [8, 1, 5, 1, 1, 8] True\n111000 [8, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 43.112 %\n111001 [8, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 38.879999999999995 %\n111010 [8, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 41.74 %\n111011 [8, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 39.976 %\n111100 [8, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 37.824000000000005 %\n111101 [8, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 41.484 %\n111110 [8, 1, 6, 1, 1, 7] True\nAccuracy of the network on the 10000 test images: 42.284 %\n111111 [8, 1, 6, 1, 1, 8] True\nAccuracy of the network on the 10000 test images: 43.268 %\n[8, 1, 5, 1, 1, 8]\nFinal Judge:\nAccuracy of the network on the 10000 test images: 70.77 %\n","output_type":"stream"}]}]}