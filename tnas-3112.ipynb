{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-30T13:37:16.287581Z","iopub.status.busy":"2022-12-30T13:37:16.287216Z","iopub.status.idle":"2022-12-30T13:37:16.335894Z","shell.execute_reply":"2022-12-30T13:37:16.334758Z","shell.execute_reply.started":"2022-12-30T13:37:16.287550Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","id_op = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\n","\n","node_ops = [[]]*10\n","node_ops[0] = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\n","node_ops[1] = ['none']\n","node_ops[2] = ['nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\n","node_ops[3] = ['nor_conv_1x1','nor_conv_3x3']\n","node_ops[4] = ['skip_connect','avg_pool_3x3']\n","node_ops[5] = ['nor_conv_1x1']\n","node_ops[6] = ['nor_conv_3x3']\n","node_ops[7] = ['skip_connect']\n","node_ops[8] = ['avg_pool_3x3']\n","\n","L = [(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)]\n","\n","'''\n","References: NATS-Bench source code (on topology search space (tss)): \n","https://github.com/D-X-Y/AutoDL-Projects/tree/f46486e21b71ae6459a700be720d7648b5429569/xautodl\n","\n","The following classes are modified compared to original version: MixedOp, Cell\n","\n","Arch (seems to) play the role of Gentotypes in the original implementation\n","Cell (seems to) play the role of InferCell in the original implementation\n","'''\n","\n","OPS = {\n","    \"none\": lambda C_in, C_out, stride, affine, track_running_stats: Zero(\n","        C_in, C_out, stride\n","    ),\n","    \"avg_pool_3x3\": lambda C_in, C_out, stride, affine, track_running_stats: POOLING(\n","        C_in, C_out, stride, \"avg\", affine, track_running_stats\n","    ),\n","    \"nor_conv_3x3\": lambda C_in, C_out, stride, affine, track_running_stats: ReLUConvBN(\n","        C_in,\n","        C_out,\n","        (3, 3),\n","        (stride, stride),\n","        (1, 1),\n","        (1, 1),\n","        affine,\n","        track_running_stats,\n","    ),\n","    \"nor_conv_1x1\": lambda C_in, C_out, stride, affine, track_running_stats: ReLUConvBN(\n","        C_in,\n","        C_out,\n","        (1, 1),\n","        (stride, stride),\n","        (0, 0),\n","        (1, 1),\n","        affine,\n","        track_running_stats,\n","    ),\n","    \"skip_connect\": lambda C_in, C_out, stride, affine, track_running_stats: Identity()\n","    if stride == 1 and C_in == C_out\n","    else FactorizedReduce(C_in, C_out, stride, affine, track_running_stats),\n","}\n","\n","class ReLUConvBN(nn.Module):\n","    def __init__(\n","        self,\n","        C_in,\n","        C_out,\n","        kernel_size,\n","        stride,\n","        padding,\n","        dilation,\n","        affine,\n","        track_running_stats=True,\n","    ):\n","        super(ReLUConvBN, self).__init__()\n","        self.op = nn.Sequential(\n","            nn.ReLU(inplace=False),\n","            nn.Conv2d(\n","                C_in,\n","                C_out,\n","                kernel_size,\n","                stride=stride,\n","                padding=padding,\n","                dilation=dilation,\n","                bias=not affine,\n","            ),\n","            nn.BatchNorm2d(\n","                C_out, affine=affine, track_running_stats=track_running_stats\n","            ),\n","        )\n","\n","    def forward(self, x):\n","        return self.op(x)\n","\n","class POOLING(nn.Module):\n","    def __init__(\n","        self, C_in, C_out, stride, mode, affine=True, track_running_stats=True\n","    ):\n","        super(POOLING, self).__init__()\n","        if C_in == C_out:\n","            self.preprocess = None\n","        else:\n","            self.preprocess = ReLUConvBN(\n","                C_in, C_out, 1, 1, 0, 1, affine, track_running_stats\n","            )\n","        if mode == \"avg\":\n","            self.op = nn.AvgPool2d(3, stride=stride, padding=1, count_include_pad=False)\n","        elif mode == \"max\":\n","            self.op = nn.MaxPool2d(3, stride=stride, padding=1)\n","        else:\n","            raise ValueError(\"Invalid mode={:} in POOLING\".format(mode))\n","\n","    def forward(self, inputs):\n","        if self.preprocess:\n","            x = self.preprocess(inputs)\n","        else:\n","            x = inputs\n","        return self.op(x)\n","\n","class Identity(nn.Module):\n","    def __init__(self):\n","        super(Identity, self).__init__()\n","\n","    def forward(self, x):\n","        return x\n","\n","class Zero(nn.Module):\n","    def __init__(self, C_in, C_out, stride):\n","        super(Zero, self).__init__()\n","        self.C_in = C_in\n","        self.C_out = C_out\n","        self.stride = stride\n","        self.is_zero = True\n","\n","    def forward(self, x):\n","        if self.C_in == self.C_out:\n","            if self.stride == 1:\n","                return x.mul(0.0)\n","            else:\n","                return x[:, :, :: self.stride, :: self.stride].mul(0.0)\n","        else:\n","            shape = list(x.shape)\n","            shape[1] = self.C_out\n","            zeros = x.new_zeros(shape, dtype=x.dtype, device=x.device)\n","            return zeros\n","\n","    def extra_repr(self):\n","        return \"C_in={C_in}, C_out={C_out}, stride={stride}\".format(**self.__dict__)\n","\n","class FactorizedReduce(nn.Module):\n","    def __init__(self, C_in, C_out, stride, affine, track_running_stats):\n","        super(FactorizedReduce, self).__init__()\n","        self.stride = stride\n","        self.C_in = C_in\n","        self.C_out = C_out\n","        self.relu = nn.ReLU(inplace=False)\n","        if stride == 2:\n","            # assert C_out % 2 == 0, 'C_out : {:}'.format(C_out)\n","            C_outs = [C_out // 2, C_out - C_out // 2]\n","            self.convs = nn.ModuleList()\n","            for i in range(2):\n","                self.convs.append(\n","                    nn.Conv2d(\n","                        C_in, C_outs[i], 1, stride=stride, padding=0, bias=not affine\n","                    )\n","                )\n","            self.pad = nn.ConstantPad2d((0, 1, 0, 1), 0)\n","        elif stride == 1:\n","            self.conv = nn.Conv2d(\n","                C_in, C_out, 1, stride=stride, padding=0, bias=not affine\n","            )\n","        else:\n","            raise ValueError(\"Invalid stride : {:}\".format(stride))\n","        self.bn = nn.BatchNorm2d(\n","            C_out, affine=affine, track_running_stats=track_running_stats\n","        )\n","\n","    def forward(self, x):\n","        if self.stride == 2:\n","            x = self.relu(x)\n","            y = self.pad(x)\n","            out = torch.cat([self.convs[0](x), self.convs[1](y[:, :, 1:, 1:])], dim=1)\n","        else:\n","            out = self.conv(x)\n","        out = self.bn(out)\n","        return out\n","\n","    def extra_repr(self):\n","        return \"C_in={C_in}, C_out={C_out}, stride={stride}\".format(**self.__dict__)\n","\n","class MixedOp(nn.Module):\n","    def __init__(self, ops, C_in, C_out, stride=1, affine= True, track_running_stats= True):\n","        super(MixedOp, self).__init__()\n","        self.C_in = C_in\n","        self.C_out = C_out\n","        self.affine = affine\n","        self.track_running_stats = track_running_stats\n","        self.stride = stride\n","        self.ops = nn.ModuleList()\n","        for op in ops:\n","            cuda_op = OPS[op](C_in, C_out, stride, affine, track_running_stats)\n","            self.ops.append(cuda_op)\n","\n","    def forward(self, x):\n","        rx = torch.zeros_like(x)\n","        for st_op in self.ops:\n","            rx = rx + st_op(x)\n","        return rx\n","\n","class Cell(nn.Module):\n","    def __init__(self, Arch, C_in, C_out, stride, affine= True, track_running_stats= True):\n","        super(Cell, self).__init__()\n","        self.Arch = Arch\n","        self.C_in = C_in\n","        self.C_out = C_out\n","        self.affine = affine\n","        self.track_running_stats = track_running_stats\n","        self.stride = stride\n","        self.out_dim = C_out\n","        self.ops = nn.ModuleList()\n","        for i in range(6):\n","            ops = node_ops[self.Arch[i]]\n","            st_op = MixedOp(ops, C_in, C_out)\n","            self.ops.append(st_op)\n","\n","    def forward(self, x):\n","        layers = [torch.zeros_like(x)]*6\n","        layers[0] = x\n","        for i in range(6):\n","            s, t = L[i]\n","            st_op = self.ops[i]\n","            layers[t] = layers[t] + st_op(layers[s])\n","        return layers[3]\n","\n","class ResNetBasicblock(nn.Module):\n","    def __init__(self, inplanes, planes, stride, affine=True, track_running_stats=True):\n","        super(ResNetBasicblock, self).__init__()\n","        assert stride == 1 or stride == 2, \"invalid stride {:}\".format(stride)\n","        self.conv_a = ReLUConvBN(\n","            inplanes, planes, 3, stride, 1, 1, affine, track_running_stats\n","        )\n","        self.conv_b = ReLUConvBN(\n","            planes, planes, 3, 1, 1, 1, affine, track_running_stats\n","        )\n","        if stride == 2:\n","            self.downsample = nn.Sequential(\n","                nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n","                nn.Conv2d(\n","                    inplanes, planes, kernel_size=1, stride=1, padding=0, bias=False\n","                ),\n","            )\n","        elif inplanes != planes:\n","            self.downsample = ReLUConvBN(\n","                inplanes, planes, 1, 1, 0, 1, affine, track_running_stats\n","            )\n","        else:\n","            self.downsample = None\n","        self.in_dim = inplanes\n","        self.out_dim = planes\n","        self.stride = stride\n","        self.num_conv = 2\n","\n","    def extra_repr(self):\n","        string = \"{name}(inC={in_dim}, outC={out_dim}, stride={stride})\".format(\n","            name=self.__class__.__name__, **self.__dict__\n","        )\n","        return string\n","\n","    def forward(self, inputs):\n","\n","        basicblock = self.conv_a(inputs)\n","        basicblock = self.conv_b(basicblock)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(inputs)\n","        else:\n","            residual = inputs\n","        return residual + basicblock\n","\n","class TinyNetwork(nn.Module):\n","    def __init__(self, C, N, Arch, num_classes):\n","        '''\n","        Initial Macro parameters (according to NAS-Bench-201):\n","        C: Input channel of 1st stack: 16\n","        N: Number of DAG-Cell/stack: 5\n","        num_classes: =10 on CIFAR-10 (probably?)\n","        '''\n","        super(TinyNetwork, self).__init__()\n","        self._C = C\n","        self._layerN = N\n","        self.Arch = Arch\n","        self.num_classes = num_classes\n","\n","        self.stem = nn.Sequential(\n","            nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(C)\n","        )\n","\n","        layer_channels = [C] * N + [C * 2] + [C * 2] * N + [C * 4] + [C * 4] * N\n","        layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n","\n","        C_prev = C\n","        self.cells = nn.ModuleList()\n","        for index, (C_curr, reduction) in enumerate(\n","            zip(layer_channels, layer_reductions)\n","        ):\n","            if reduction:\n","                cell = ResNetBasicblock(C_prev, C_curr, 2, True)\n","            else:\n","                cell = Cell(Arch, C_prev, C_curr, 1)\n","            self.cells.append(cell)\n","            C_prev = cell.out_dim\n","        self._Layer = len(self.cells)\n","\n","        self.lastact = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n","        self.global_pooling = nn.AdaptiveAvgPool2d(1)\n","        self.classifier = nn.Linear(C_prev, num_classes)\n","\n","    def get_message(self):\n","        string = self.extra_repr()\n","        for i, cell in enumerate(self.cells):\n","            string += \"\\n {:02d}/{:02d} :: {:}\".format(\n","                i, len(self.cells), cell.extra_repr()\n","            )\n","        return string\n","\n","    def extra_repr(self):\n","        return \"{name}(C={_C}, N={_layerN}, L={_Layer})\".format(\n","            name=self.__class__.__name__, **self.__dict__\n","        )\n","\n","    def forward(self, inputs):\n","        feature = self.stem(inputs)\n","        for i, cell in enumerate(self.cells):\n","            feature = cell(feature)\n","\n","        out = self.lastact(feature)\n","        out = self.global_pooling(out)\n","        out = out.view(out.size(0), -1)\n","        logits = self.classifier(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T13:37:30.796484Z","iopub.status.busy":"2022-12-30T13:37:30.796114Z","iopub.status.idle":"2022-12-30T13:37:32.298053Z","shell.execute_reply":"2022-12-30T13:37:32.297131Z","shell.execute_reply.started":"2022-12-30T13:37:30.796453Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","num_epochs = 2\n","batch_size = 256\n","\n","trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n","                                        download=True, transform=transform)\n","train_indices = range(25000)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=False,sampler=train_indices)\n","#tao sẽ thêm phần validation sau\n","\n","val_indices = range(25000,50000)\n","valloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=False,sampler=val_indices)\n","\n","final_indices = range(50000)\n","finalloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=False,sampler=final_indices)\n","\n","testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","def get_metric(Arch, final= False):\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    net = TinyNetwork(16,5,Arch,10)\n","    net.to(device)\n","    criterion  = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9,nesterov=True,weight_decay=0.0005)\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max = 200,eta_min=0)\n","\n","    global num_epochs\n","    \n","    if final:\n","        num_epochs = 12\n","    else:\n","        num_epochs = 2\n","    \n","    for epoch in range(num_epochs):\n","        net.train()\n","        scheduler.step()\n","        loader = trainloader\n","        if final:\n","            loader = finalloader\n","        for inputs, labels in loader:\n","            inputs,labels = inputs.to(device),labels.to(device)\n","            # get the inputs; data is a list of [inputs, labels]\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs.float())\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","        \n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        net.eval()\n","        loader = valloader\n","        if final:\n","            loader = testloader\n","        for inputs, labels in loader: #về sau ở đây t sẽ thay bằng validation\n","            inputs,labels = inputs.to(device),labels.to(device)\n","            outputs = net(inputs.float())\n","            loss = criterion(outputs,labels)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.cpu().detach().size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        acc = float(correct/total)\n","        if final:\n","            print('Final Judge:')\n","        print(f'Accuracy of the network on the 10000 test images: {100 * acc} %')\n","    return acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T13:37:39.638839Z","iopub.status.busy":"2022-12-30T13:37:39.638451Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Build_masks: Done\n","0 [1, 1, 1, 1, 1, 1]\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the 10000 test images: 10.036000000000001 %\n","000000 [1, 1, 1, 1, 1, 1] False\n","000001 [1, 1, 1, 1, 1, 2] False\n","000010 [1, 1, 1, 1, 2, 1] False\n","000011 [1, 1, 1, 1, 2, 2] False\n","000100 [1, 1, 1, 2, 1, 1] False\n","000101 [1, 1, 1, 2, 1, 2] False\n","000110 [1, 1, 1, 2, 2, 1] False\n","000111 [1, 1, 1, 2, 2, 2] False\n","001000 [1, 1, 2, 1, 1, 1] True\n","Accuracy of the network on the 10000 test images: 32.504 %\n","001001 [1, 1, 2, 1, 1, 2] False\n","001010 [1, 1, 2, 1, 2, 1] False\n","001011 [1, 1, 2, 1, 2, 2] False\n","001100 [1, 1, 2, 2, 1, 1] True\n","Accuracy of the network on the 10000 test images: 38.635999999999996 %\n","001101 [1, 1, 2, 2, 1, 2] False\n","001110 [1, 1, 2, 2, 2, 1] False\n","001111 [1, 1, 2, 2, 2, 2] False\n","010000 [1, 2, 1, 1, 1, 1] False\n","010001 [1, 2, 1, 1, 1, 2] True\n","Accuracy of the network on the 10000 test images: 40.92 %\n","010010 [1, 2, 1, 1, 2, 1] False\n","010011 [1, 2, 1, 1, 2, 2] True\n","Accuracy of the network on the 10000 test images: 34.252 %\n","010100 [1, 2, 1, 2, 1, 1] False\n","010101 [1, 2, 1, 2, 1, 2] False\n","010110 [1, 2, 1, 2, 2, 1] False\n","010111 [1, 2, 1, 2, 2, 2] False\n","011000 [1, 2, 2, 1, 1, 1] True\n"]}],"source":["import random\n","import numpy as np\n","import pandas as pd \n","import matplotlib.pyplot as plt\n","import time\n","# from nas_201_api import NASBench201API as API\n","\n","# Operation tree design\n","node_ops = [[]]*9 # operations on id-th node\n","e = [[]]*9 # edge list\n","par = [-1]*9 # parent list\n","\n","e[0] = [1,2]\n","e[2] = [3,4]\n","e[3] = [5,6]\n","e[4] = [7,8]\n","\n","par[1] = 0\n","par[2] = 0\n","par[3] = 2\n","par[4] = 2\n","par[5] = 3\n","par[6] = 3\n","par[7] = 4\n","par[8] = 4\n","\n","\n","node_ops[0] = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\n","node_ops[1] = ['none']\n","node_ops[2] = ['nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\n","node_ops[3] = ['nor_conv_1x1','nor_conv_3x3']\n","node_ops[4] = ['skip_connect','avg_pool_3x3']\n","node_ops[5] = ['nor_conv_1x1']\n","node_ops[6] = ['nor_conv_3x3']\n","node_ops[7] = ['skip_connect']\n","node_ops[8] = ['avg_pool_3x3']\n","\n","# Cell's DAG edge list\n","L = [(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)]\n","\n","# Encoding candidates and operations\n","id_op = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\n","masks = []\n","\n","def To_mask(num):\n","    res = ''\n","    while(num > 0):\n","        res += str(num % 2)\n","        num = int(num/2)\n","    while(len(res) < 6):\n","        res += '0'\n","    res = res[::-1]\n","    return res\n","\n","def Build_masks():\n","    mask_len = 2**6 - 1\n","    for i in range(mask_len + 1):\n","        masks.append(To_mask(i))\n","    print(\"Build_masks: Done\")\n","\n","def Build_cand_arch(Arch, mask):\n","    Cand_arch = []\n","    Len = len(mask)\n","    for i in range(Len):\n","        if len(e[Arch[i]]) < 2:\n","            Cand_arch.append(Arch[i])\n","            continue\n","        o0 = e[Arch[i]][0]\n","        o1 = e[Arch[i]][1]\n","        b = mask[i]\n","        op = o0\n","        if b == '1':\n","            op = o1\n","        Cand_arch.append(op)\n","    return Cand_arch\n","\n","def Score(Arch, final= False):\n","    return get_metric(Arch, final)\n","\n","def Check_connected(Arch):\n","    '''\n","    if (Arch[0] == 1) and (Arch[1] == 1) and (Arch[2] == 1):\n","        return False\n","    if (Arch[4] == 1) and (Arch[5] == 1):\n","        return False\n","    '''\n","    fr = [True]*4\n","    fr[0] = False\n","    for i in range(6):\n","        s, t = L[i]\n","        if Arch[i] == 1:\n","            continue\n","        fr[t] = (fr[t] and fr[s])\n","    return not fr[3]\n","\n","def BFS_T_o():\n","    Arch = [0,0,0,0,0,0]\n","    q = []\n","    q.insert(0,0) # queue.push()\n","    for i in range(3):\n","        Cur_arch = Build_cand_arch(Arch, To_mask(0))\n","        print(i, Cur_arch)\n","        score = Score(Cur_arch)\n","        for mask in masks:\n","            Cand_arch = Build_cand_arch(Arch, mask)\n","            print(mask, Cand_arch, Check_connected(Cand_arch))\n","            if not Check_connected(Cand_arch):\n","                continue\n","            if Cur_arch == Cand_arch: \n","                continue\n","            cand_score = Score(Cand_arch)\n","            if score < cand_score:\n","                Cur_arch = Cand_arch\n","                score = cand_score\n","        Arch = Cur_arch\n","    print(Arch)\n","    final_score = Score(Arch, final= True)\n","\n","Build_masks()\n","BFS_T_o()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"}}},"nbformat":4,"nbformat_minor":4}
