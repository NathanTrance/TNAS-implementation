{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nid_op = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\n\nnode_ops = [[]]*10\nnode_ops[0] = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nnode_ops[1] = ['none']\nnode_ops[2] = ['nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nnode_ops[3] = ['nor_conv_1x1','nor_conv_3x3']\nnode_ops[4] = ['skip_connect','avg_pool_3x3']\nnode_ops[5] = ['nor_conv_1x1']\nnode_ops[6] = ['nor_conv_3x3']\nnode_ops[7] = ['skip_connect']\nnode_ops[8] = ['avg_pool_3x3']\n\nL = [(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)]\n\n'''\nReferences: NATS-Bench source code (on topology search space (tss)): \nhttps://github.com/D-X-Y/AutoDL-Projects/tree/f46486e21b71ae6459a700be720d7648b5429569/xautodl\n\nThe following classes are modified compared to original version: MixedOp, Cell\n\nArch (seems to) play the role of Gentotypes in the original implementation\nCell (seems to) play the role of InferCell in the original implementation\n'''\n\nOPS = {\n    \"none\": lambda C_in, C_out, stride, affine, track_running_stats: Zero(\n        C_in, C_out, stride\n    ),\n    \"avg_pool_3x3\": lambda C_in, C_out, stride, affine, track_running_stats: POOLING(\n        C_in, C_out, stride, \"avg\", affine, track_running_stats\n    ),\n    \"nor_conv_3x3\": lambda C_in, C_out, stride, affine, track_running_stats: ReLUConvBN(\n        C_in,\n        C_out,\n        (3, 3),\n        (stride, stride),\n        (1, 1),\n        (1, 1),\n        affine,\n        track_running_stats,\n    ),\n    \"nor_conv_1x1\": lambda C_in, C_out, stride, affine, track_running_stats: ReLUConvBN(\n        C_in,\n        C_out,\n        (1, 1),\n        (stride, stride),\n        (0, 0),\n        (1, 1),\n        affine,\n        track_running_stats,\n    ),\n    \"skip_connect\": lambda C_in, C_out, stride, affine, track_running_stats: Identity()\n    if stride == 1 and C_in == C_out\n    else FactorizedReduce(C_in, C_out, stride, affine, track_running_stats),\n}\n\nclass ReLUConvBN(nn.Module):\n    def __init__(\n        self,\n        C_in,\n        C_out,\n        kernel_size,\n        stride,\n        padding,\n        dilation,\n        affine,\n        track_running_stats=True,\n    ):\n        super(ReLUConvBN, self).__init__()\n        self.op = nn.Sequential(\n            nn.ReLU(inplace=False),\n            nn.Conv2d(\n                C_in,\n                C_out,\n                kernel_size,\n                stride=stride,\n                padding=padding,\n                dilation=dilation,\n                bias=not affine,\n            ),\n            nn.BatchNorm2d(\n                C_out, affine=affine, track_running_stats=track_running_stats\n            ),\n        )\n\n    def forward(self, x):\n        return self.op(x)\n\nclass POOLING(nn.Module):\n    def __init__(\n        self, C_in, C_out, stride, mode, affine=True, track_running_stats=True\n    ):\n        super(POOLING, self).__init__()\n        if C_in == C_out:\n            self.preprocess = None\n        else:\n            self.preprocess = ReLUConvBN(\n                C_in, C_out, 1, 1, 0, 1, affine, track_running_stats\n            )\n        if mode == \"avg\":\n            self.op = nn.AvgPool2d(3, stride=stride, padding=1, count_include_pad=False)\n        elif mode == \"max\":\n            self.op = nn.MaxPool2d(3, stride=stride, padding=1)\n        else:\n            raise ValueError(\"Invalid mode={:} in POOLING\".format(mode))\n\n    def forward(self, inputs):\n        if self.preprocess:\n            x = self.preprocess(inputs)\n        else:\n            x = inputs\n        return self.op(x)\n\nclass Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n\n    def forward(self, x):\n        return x\n\nclass Zero(nn.Module):\n    def __init__(self, C_in, C_out, stride):\n        super(Zero, self).__init__()\n        self.C_in = C_in\n        self.C_out = C_out\n        self.stride = stride\n        self.is_zero = True\n\n    def forward(self, x):\n        if self.C_in == self.C_out:\n            if self.stride == 1:\n                return x.mul(0.0)\n            else:\n                return x[:, :, :: self.stride, :: self.stride].mul(0.0)\n        else:\n            shape = list(x.shape)\n            shape[1] = self.C_out\n            zeros = x.new_zeros(shape, dtype=x.dtype, device=x.device)\n            return zeros\n\n    def extra_repr(self):\n        return \"C_in={C_in}, C_out={C_out}, stride={stride}\".format(**self.__dict__)\n\nclass FactorizedReduce(nn.Module):\n    def __init__(self, C_in, C_out, stride, affine, track_running_stats):\n        super(FactorizedReduce, self).__init__()\n        self.stride = stride\n        self.C_in = C_in\n        self.C_out = C_out\n        self.relu = nn.ReLU(inplace=False)\n        if stride == 2:\n            # assert C_out % 2 == 0, 'C_out : {:}'.format(C_out)\n            C_outs = [C_out // 2, C_out - C_out // 2]\n            self.convs = nn.ModuleList()\n            for i in range(2):\n                self.convs.append(\n                    nn.Conv2d(\n                        C_in, C_outs[i], 1, stride=stride, padding=0, bias=not affine\n                    )\n                )\n            self.pad = nn.ConstantPad2d((0, 1, 0, 1), 0)\n        elif stride == 1:\n            self.conv = nn.Conv2d(\n                C_in, C_out, 1, stride=stride, padding=0, bias=not affine\n            )\n        else:\n            raise ValueError(\"Invalid stride : {:}\".format(stride))\n        self.bn = nn.BatchNorm2d(\n            C_out, affine=affine, track_running_stats=track_running_stats\n        )\n\n    def forward(self, x):\n        if self.stride == 2:\n            x = self.relu(x)\n            y = self.pad(x)\n            out = torch.cat([self.convs[0](x), self.convs[1](y[:, :, 1:, 1:])], dim=1)\n        else:\n            out = self.conv(x)\n        out = self.bn(out)\n        return out\n\n    def extra_repr(self):\n        return \"C_in={C_in}, C_out={C_out}, stride={stride}\".format(**self.__dict__)\n\nclass MixedOp(nn.Module):\n    def __init__(self, ops, C_in, C_out, stride=1, affine= True, track_running_stats= True):\n        super(MixedOp, self).__init__()\n        self.C_in = C_in\n        self.C_out = C_out\n        self.affine = affine\n        self.track_running_stats = track_running_stats\n        self.stride = stride\n        self.ops = nn.ModuleList()\n        for op in ops:\n            cuda_op = OPS[op](C_in, C_out, stride, affine, track_running_stats)\n            self.ops.append(cuda_op)\n\n    def forward(self, x):\n        rx = torch.zeros_like(x)\n        for st_op in self.ops:\n            rx = rx + st_op(x)\n        return rx\n\nclass Cell(nn.Module):\n    def __init__(self, Arch, C_in, C_out, stride, affine= True, track_running_stats= True):\n        super(Cell, self).__init__()\n        self.Arch = Arch\n        self.C_in = C_in\n        self.C_out = C_out\n        self.affine = affine\n        self.track_running_stats = track_running_stats\n        self.stride = stride\n        self.out_dim = C_out\n        self.ops = nn.ModuleList()\n        for i in range(6):\n            ops = node_ops[self.Arch[i]]\n            st_op = MixedOp(ops, C_in, C_out)\n            self.ops.append(st_op)\n\n    def forward(self, x):\n        layers = [torch.zeros_like(x)]*6\n        layers[0] = x\n        for i in range(6):\n            s, t = L[i]\n            st_op = self.ops[i]\n            layers[t] = layers[t] + st_op(layers[s])\n        return layers[3]\n\nclass ResNetBasicblock(nn.Module):\n    def __init__(self, inplanes, planes, stride, affine=True, track_running_stats=True):\n        super(ResNetBasicblock, self).__init__()\n        assert stride == 1 or stride == 2, \"invalid stride {:}\".format(stride)\n        self.conv_a = ReLUConvBN(\n            inplanes, planes, 3, stride, 1, 1, affine, track_running_stats\n        )\n        self.conv_b = ReLUConvBN(\n            planes, planes, 3, 1, 1, 1, affine, track_running_stats\n        )\n        if stride == 2:\n            self.downsample = nn.Sequential(\n                nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n                nn.Conv2d(\n                    inplanes, planes, kernel_size=1, stride=1, padding=0, bias=False\n                ),\n            )\n        elif inplanes != planes:\n            self.downsample = ReLUConvBN(\n                inplanes, planes, 1, 1, 0, 1, affine, track_running_stats\n            )\n        else:\n            self.downsample = None\n        self.in_dim = inplanes\n        self.out_dim = planes\n        self.stride = stride\n        self.num_conv = 2\n\n    def extra_repr(self):\n        string = \"{name}(inC={in_dim}, outC={out_dim}, stride={stride})\".format(\n            name=self.__class__.__name__, **self.__dict__\n        )\n        return string\n\n    def forward(self, inputs):\n\n        basicblock = self.conv_a(inputs)\n        basicblock = self.conv_b(basicblock)\n\n        if self.downsample is not None:\n            residual = self.downsample(inputs)\n        else:\n            residual = inputs\n        return residual + basicblock\n\nclass TinyNetwork(nn.Module):\n    def __init__(self, C, N, Arch, num_classes):\n        '''\n        Initial Macro parameters (according to NAS-Bench-201):\n        C: Input channel of 1st stack: 16\n        N: Number of DAG-Cell/stack: 5\n        num_classes: =10 on CIFAR-10 (probably?)\n        '''\n        super(TinyNetwork, self).__init__()\n        self._C = C\n        self._layerN = N\n        self.Arch = Arch\n        self.num_classes = num_classes\n\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, C, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(C)\n        )\n\n        layer_channels = [C] * N + [C * 2] + [C * 2] * N + [C * 4] + [C * 4] * N\n        layer_reductions = [False] * N + [True] + [False] * N + [True] + [False] * N\n\n        C_prev = C\n        self.cells = nn.ModuleList()\n        for index, (C_curr, reduction) in enumerate(\n            zip(layer_channels, layer_reductions)\n        ):\n            if reduction:\n                cell = ResNetBasicblock(C_prev, C_curr, 2, True)\n            else:\n                cell = Cell(Arch, C_prev, C_curr, 1)\n            self.cells.append(cell)\n            C_prev = cell.out_dim\n        self._Layer = len(self.cells)\n\n        self.lastact = nn.Sequential(nn.BatchNorm2d(C_prev), nn.ReLU(inplace=True))\n        self.global_pooling = nn.AdaptiveAvgPool2d(1)\n        self.classifier = nn.Linear(C_prev, num_classes)\n\n    def get_message(self):\n        string = self.extra_repr()\n        for i, cell in enumerate(self.cells):\n            string += \"\\n {:02d}/{:02d} :: {:}\".format(\n                i, len(self.cells), cell.extra_repr()\n            )\n        return string\n\n    def extra_repr(self):\n        return \"{name}(C={_C}, N={_layerN}, L={_Layer})\".format(\n            name=self.__class__.__name__, **self.__dict__\n        )\n\n    def forward(self, inputs):\n        feature = self.stem(inputs)\n        for i, cell in enumerate(self.cells):\n            feature = cell(feature)\n\n        out = self.lastact(feature)\n        out = self.global_pooling(out)\n        out = out.view(out.size(0), -1)\n        logits = self.classifier(out)\n\n        return out","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-01-03T00:57:26.180063Z","iopub.execute_input":"2023-01-03T00:57:26.180885Z","iopub.status.idle":"2023-01-03T00:57:28.084402Z","shell.execute_reply.started":"2023-01-03T00:57:26.180753Z","shell.execute_reply":"2023-01-03T00:57:28.083299Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torch.nn.functional as F\n\ntransform_train = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.RandomCrop(size=(32,32),padding=4),\n     transforms.RandomHorizontalFlip(p=0.5),\n    #  transforms.RandomVerticalFlip(p=0.5), hinata\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n)\n\nnum_epochs = 2\nbatch_size = 256\n\n#trainset lấy 25000 cái đầu, lấy transform_train\ntrainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n                                        download=True, transform=transform_train)\ntrain_indices = range(25000)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=False,sampler=train_indices)\n\n#valset gồm 25000 cái sau, chỉ cần normalize\nvalset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n                                        download=True, transform=transform)\nval_indices = range(25000,50000)\nvalloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=False,sampler=val_indices)\n\n#finalset gồm cả 50000 lun, dùng transform_train\nfinalset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n                                        download=True, transform=transform_train)\nfinal_indices = range(50000)\nfinalloader = torch.utils.data.DataLoader(finalset, batch_size=batch_size,\n                                          shuffle=False,sampler=final_indices)\n\n#testset chỉ cần normalize\ntestset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\ndef get_metric(Arch, final= False):\n    if final:\n        num_epochs = 200\n    else:\n        num_epochs = 2\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    net = TinyNetwork(16,5,Arch,10)\n    net.to(device)\n    criterion  = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9,nesterov=True,weight_decay=0.0005)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max = num_epochs,eta_min=0)\n    \n    for epoch in range(num_epochs):\n        net.train()\n#         scheduler.step()\n        loader = trainloader\n        if final:\n            loader = finalloader\n        for inputs, labels in loader:\n            inputs,labels = inputs.to(device),labels.to(device)\n            # get the inputs; data is a list of [inputs, labels]\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs.float())\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        scheduler.step()\n        \n    with torch.no_grad():\n        correct = 0\n        total = 0\n        net.eval()\n        loader = valloader\n        if final:\n            loader = testloader\n        for inputs, labels in loader: #về sau ở đây t sẽ thay bằng validation\n            inputs,labels = inputs.to(device),labels.to(device)\n            outputs = net(inputs.float())\n            loss = criterion(outputs,labels)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.cpu().detach().size(0)\n            correct += (predicted == labels).sum().item()\n\n        acc = float(correct/total)\n        if final:\n            print('Final Judge:')\n        print(f'Accuracy of the network on the 10000 test images: {100 * acc} %')\n    return acc","metadata":{"execution":{"iopub.status.busy":"2023-01-03T00:57:41.317290Z","iopub.execute_input":"2023-01-03T00:57:41.317836Z","iopub.status.idle":"2023-01-03T00:57:51.620847Z","shell.execute_reply.started":"2023-01-03T00:57:41.317802Z","shell.execute_reply":"2023-01-03T00:57:51.619756Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170498071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c32997c7fbeb448ca29b8d843df00ca9"}},"metadata":{}},{"name":"stdout","text":"Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\nFiles already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport time\n# from nas_201_api import NASBench201API as API\n\n# Operation tree design\nnode_ops = [[]]*9 # operations on id-th node\ne = [[]]*9 # edge list\npar = [-1]*9 # parent list\n\ne[0] = [1,2]\ne[2] = [3,4]\ne[3] = [5,6]\ne[4] = [7,8]\n\npar[1] = 0\npar[2] = 0\npar[3] = 2\npar[4] = 2\npar[5] = 3\npar[6] = 3\npar[7] = 4\npar[8] = 4\n\n\nnode_ops[0] = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nnode_ops[1] = ['none']\nnode_ops[2] = ['nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nnode_ops[3] = ['nor_conv_1x1','nor_conv_3x3']\nnode_ops[4] = ['skip_connect','avg_pool_3x3']\nnode_ops[5] = ['nor_conv_1x1']\nnode_ops[6] = ['nor_conv_3x3']\nnode_ops[7] = ['skip_connect']\nnode_ops[8] = ['avg_pool_3x3']\n\n# Cell's DAG edge list\nL = [(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)]\n\n# Encoding candidates and operations\nid_op = ['none','nor_conv_1x1','nor_conv_3x3','skip_connect','avg_pool_3x3']\nmasks = []\n\n# Arch archive:\narchive = [0]*999999\n\ndef To_mask(num):\n    res = ''\n    while(num > 0):\n        res += str(num % 2)\n        num = int(num/2)\n    while(len(res) < 6):\n        res += '0'\n    res = res[::-1]\n    return res\n\ndef Build_masks():\n    mask_len = 2**6 - 1\n    for i in range(mask_len + 1):\n        masks.append(To_mask(i))\n    print(\"Build_masks: Done\")\n    \ndef Int_encode(Arch):\n    res = 0\n    for i in range(6):\n        res = res*10 + Arch[i]\n    return res\n\ndef Build_cand_arch(Arch, mask):\n    Cand_arch = []\n    Len = len(mask)\n    for i in range(Len):\n        if len(e[Arch[i]]) < 2:\n            Cand_arch.append(Arch[i])\n            continue\n        o0 = e[Arch[i]][0]\n        o1 = e[Arch[i]][1]\n        b = mask[i]\n        op = o0\n        if b == '1':\n            op = o1\n        Cand_arch.append(op)\n    return Cand_arch\n\ndef Score(Arch,final= False):\n    score = 0.0\n    tmp = 3\n    if final:\n        tmp = 1\n    for i in range(tmp):\n        tmp_score = get_metric(Arch, final)\n        score += tmp_score\n    score = float(score/tmp)\n    print('Average score: ' + str(score))\n    return score\n\ndef Check_connected(Arch):\n    '''\n    if (Arch[0] == 1) and (Arch[1] == 1) and (Arch[2] == 1):\n        return False\n    if (Arch[4] == 1) and (Arch[5] == 1):\n        return False\n    '''\n    fr = [True]*4\n    fr[0] = False\n    for i in range(6):\n        s, t = L[i]\n        if Arch[i] == 1:\n            continue\n        fr[t] = (fr[t] and fr[s])\n    if fr[3]:\n        return False\n    for i in range(6):\n        s, t = L[i]\n        if Arch[i] == 1:\n            continue\n        if fr[s] or fr[t]:\n            return False\n    \n    fr = [True]*4\n    fr[3] = False\n    for i in range(6):\n        j = 5-i\n        t, s = L[j]\n        if Arch[j] == 1:\n            continue\n        fr[t] = (fr[t] and fr[s])\n    for i in range(6):\n        s, t = L[i]\n        if Arch[i] == 1:\n            continue\n        if fr[t] or fr[s]:\n            return False\n        \n    return True\n\ndef BFS_T_o():\n    Arch = [0,0,0,0,0,0]\n    for i in range(3):\n        Cur_arch = Build_cand_arch(Arch, To_mask(0))\n        print(i, Cur_arch)\n        score = Score(Cur_arch)\n        for mask in masks:\n            Cand_arch = Build_cand_arch(Arch, mask)\n            Cand_arch_id = Int_encode(Cand_arch)\n            print(mask, Cand_arch, Check_connected(Cand_arch))\n            if not Check_connected(Cand_arch):\n                continue\n            if Cur_arch == Cand_arch: \n                continue\n            if archive[Cand_arch_id] != 0:\n                continue\n            else:\n                cand_score = Score(Cand_arch)\n                archive[Cand_arch_id] = cand_score\n            if score < cand_score:\n                Cur_arch = Cand_arch\n                score = cand_score\n        Arch = Cur_arch\n    print(Arch)\n    final_score = Score(Arch,final= True)\n    return Arch, final_score\n\nBuild_masks()\nBFS_T_o()","metadata":{"execution":{"iopub.status.busy":"2023-01-03T02:25:58.874005Z","iopub.execute_input":"2023-01-03T02:25:58.875229Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Build_masks: Done\n0 [1, 1, 1, 1, 1, 1]\nAccuracy of the network on the 10000 test images: 10.036000000000001 %\nAccuracy of the network on the 10000 test images: 10.036000000000001 %\nAccuracy of the network on the 10000 test images: 10.036000000000001 %\nAverage score: 0.10036\n000000 [1, 1, 1, 1, 1, 1] False\n000001 [1, 1, 1, 1, 1, 2] False\n000010 [1, 1, 1, 1, 2, 1] False\n000011 [1, 1, 1, 1, 2, 2] False\n000100 [1, 1, 1, 2, 1, 1] False\n000101 [1, 1, 1, 2, 1, 2] False\n000110 [1, 1, 1, 2, 2, 1] False\n000111 [1, 1, 1, 2, 2, 2] False\n001000 [1, 1, 2, 1, 1, 1] True\nAccuracy of the network on the 10000 test images: 36.484 %\nAccuracy of the network on the 10000 test images: 37.344 %\nAccuracy of the network on the 10000 test images: 36.496 %\nAverage score: 0.36774666666666667\n001001 [1, 1, 2, 1, 1, 2] False\n001010 [1, 1, 2, 1, 2, 1] False\n001011 [1, 1, 2, 1, 2, 2] False\n001100 [1, 1, 2, 2, 1, 1] False\n001101 [1, 1, 2, 2, 1, 2] False\n001110 [1, 1, 2, 2, 2, 1] False\n001111 [1, 1, 2, 2, 2, 2] False\n010000 [1, 2, 1, 1, 1, 1] False\n010001 [1, 2, 1, 1, 1, 2] True\nAccuracy of the network on the 10000 test images: 37.236000000000004 %\nAccuracy of the network on the 10000 test images: 36.472 %\nAccuracy of the network on the 10000 test images: 36.944 %\nAverage score: 0.36884\n010010 [1, 2, 1, 1, 2, 1] False\n010011 [1, 2, 1, 1, 2, 2] False\n010100 [1, 2, 1, 2, 1, 1] False\n010101 [1, 2, 1, 2, 1, 2] False\n010110 [1, 2, 1, 2, 2, 1] False\n010111 [1, 2, 1, 2, 2, 2] False\n011000 [1, 2, 2, 1, 1, 1] False\n011001 [1, 2, 2, 1, 1, 2] True\nAccuracy of the network on the 10000 test images: 31.64 %\nAccuracy of the network on the 10000 test images: 36.548 %\nAccuracy of the network on the 10000 test images: 36.687999999999995 %\nAverage score: 0.3495866666666667\n011010 [1, 2, 2, 1, 2, 1] False\n011011 [1, 2, 2, 1, 2, 2] False\n011100 [1, 2, 2, 2, 1, 1] False\n011101 [1, 2, 2, 2, 1, 2] False\n011110 [1, 2, 2, 2, 2, 1] False\n011111 [1, 2, 2, 2, 2, 2] False\n100000 [2, 1, 1, 1, 1, 1] False\n100001 [2, 1, 1, 1, 1, 2] False\n100010 [2, 1, 1, 1, 2, 1] True\nAccuracy of the network on the 10000 test images: 37.128 %\nAccuracy of the network on the 10000 test images: 35.5 %\nAccuracy of the network on the 10000 test images: 35.028 %\nAverage score: 0.3588533333333333\n100011 [2, 1, 1, 1, 2, 2] False\n100100 [2, 1, 1, 2, 1, 1] False\n100101 [2, 1, 1, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 37.016 %\nAccuracy of the network on the 10000 test images: 38.64 %\nAccuracy of the network on the 10000 test images: 38.172 %\nAverage score: 0.37942666666666663\n100110 [2, 1, 1, 2, 2, 1] False\n100111 [2, 1, 1, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 35.512 %\nAccuracy of the network on the 10000 test images: 37.092000000000006 %\nAccuracy of the network on the 10000 test images: 34.924 %\nAverage score: 0.35842666666666667\n101000 [2, 1, 2, 1, 1, 1] False\n101001 [2, 1, 2, 1, 1, 2] False\n101010 [2, 1, 2, 1, 2, 1] True\nAccuracy of the network on the 10000 test images: 33.708 %\nAccuracy of the network on the 10000 test images: 36.268 %\nAccuracy of the network on the 10000 test images: 36.5 %\nAverage score: 0.35491999999999996\n101011 [2, 1, 2, 1, 2, 2] False\n101100 [2, 1, 2, 2, 1, 1] False\n101101 [2, 1, 2, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 34.964 %\nAccuracy of the network on the 10000 test images: 36.236000000000004 %\nAccuracy of the network on the 10000 test images: 32.116 %\nAverage score: 0.3443866666666667\n101110 [2, 1, 2, 2, 2, 1] False\n101111 [2, 1, 2, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 31.432 %\nAccuracy of the network on the 10000 test images: 9.912 %\nAccuracy of the network on the 10000 test images: 9.927999999999999 %\nAverage score: 0.17090666666666665\n110000 [2, 2, 1, 1, 1, 1] False\n110001 [2, 2, 1, 1, 1, 2] False\n110010 [2, 2, 1, 1, 2, 1] False\n110011 [2, 2, 1, 1, 2, 2] True\nAccuracy of the network on the 10000 test images: 34.444 %\nAccuracy of the network on the 10000 test images: 33.983999999999995 %\nAccuracy of the network on the 10000 test images: 35.352 %\nAverage score: 0.34593333333333337\n110100 [2, 2, 1, 2, 1, 1] False\n110101 [2, 2, 1, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 32.052 %\nAccuracy of the network on the 10000 test images: 38.568000000000005 %\nAccuracy of the network on the 10000 test images: 37.836 %\nAverage score: 0.36152\n110110 [2, 2, 1, 2, 2, 1] False\n110111 [2, 2, 1, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 9.927999999999999 %\nAccuracy of the network on the 10000 test images: 9.927999999999999 %\nAccuracy of the network on the 10000 test images: 9.927999999999999 %\nAverage score: 0.09928\n111000 [2, 2, 2, 1, 1, 1] False\n111001 [2, 2, 2, 1, 1, 2] False\n111010 [2, 2, 2, 1, 2, 1] False\n111011 [2, 2, 2, 1, 2, 2] True\nAccuracy of the network on the 10000 test images: 36.312 %\nAccuracy of the network on the 10000 test images: 31.328 %\nAccuracy of the network on the 10000 test images: 36.059999999999995 %\nAverage score: 0.3456666666666666\n111100 [2, 2, 2, 2, 1, 1] False\n111101 [2, 2, 2, 2, 1, 2] True\nAccuracy of the network on the 10000 test images: 26.419999999999998 %\nAccuracy of the network on the 10000 test images: 19.044 %\nAccuracy of the network on the 10000 test images: 9.852 %\nAverage score: 0.18438666666666667\n111110 [2, 2, 2, 2, 2, 1] False\n111111 [2, 2, 2, 2, 2, 2] True\nAccuracy of the network on the 10000 test images: 10.036000000000001 %\nAccuracy of the network on the 10000 test images: 10.036000000000001 %\nAccuracy of the network on the 10000 test images: 10.036000000000001 %\nAverage score: 0.10036\n1 [3, 1, 1, 3, 1, 3]\nAccuracy of the network on the 10000 test images: 21.376 %\nAccuracy of the network on the 10000 test images: 26.868 %\nAccuracy of the network on the 10000 test images: 26.816000000000003 %\nAverage score: 0.2502\n000000 [3, 1, 1, 3, 1, 3] True\n000001 [3, 1, 1, 3, 1, 4] True\nAccuracy of the network on the 10000 test images: 31.6 %\nAccuracy of the network on the 10000 test images: 30.604 %\nAccuracy of the network on the 10000 test images: 29.944 %\nAverage score: 0.30715999999999993\n000010 [3, 1, 1, 3, 1, 3] True\nAccuracy of the network on the 10000 test images: 30.215999999999998 %\nAccuracy of the network on the 10000 test images: 26.412000000000003 %\nAccuracy of the network on the 10000 test images: 30.352 %\nAverage score: 0.2899333333333333\n000011 [3, 1, 1, 3, 1, 4] True\n000100 [3, 1, 1, 4, 1, 3] True\nAccuracy of the network on the 10000 test images: 29.787999999999997 %\nAccuracy of the network on the 10000 test images: 31.680000000000003 %\nAccuracy of the network on the 10000 test images: 28.52 %\nAverage score: 0.29996\n000101 [3, 1, 1, 4, 1, 4] True\nAccuracy of the network on the 10000 test images: 35.836 %\nAccuracy of the network on the 10000 test images: 38.872 %\nAccuracy of the network on the 10000 test images: 34.58 %\nAverage score: 0.36429333333333336\n000110 [3, 1, 1, 4, 1, 3] True\n000111 [3, 1, 1, 4, 1, 4] True\n001000 [3, 1, 1, 3, 1, 3] True\n001001 [3, 1, 1, 3, 1, 4] True\n001010 [3, 1, 1, 3, 1, 3] True\n001011 [3, 1, 1, 3, 1, 4] True\n001100 [3, 1, 1, 4, 1, 3] True\n001101 [3, 1, 1, 4, 1, 4] True\n001110 [3, 1, 1, 4, 1, 3] True\n001111 [3, 1, 1, 4, 1, 4] True\n010000 [3, 1, 1, 3, 1, 3] True\n010001 [3, 1, 1, 3, 1, 4] True\n010010 [3, 1, 1, 3, 1, 3] True\n010011 [3, 1, 1, 3, 1, 4] True\n010100 [3, 1, 1, 4, 1, 3] True\n010101 [3, 1, 1, 4, 1, 4] True\n010110 [3, 1, 1, 4, 1, 3] True\n010111 [3, 1, 1, 4, 1, 4] True\n011000 [3, 1, 1, 3, 1, 3] True\n011001 [3, 1, 1, 3, 1, 4] True\n011010 [3, 1, 1, 3, 1, 3] True\n011011 [3, 1, 1, 3, 1, 4] True\n011100 [3, 1, 1, 4, 1, 3] True\n011101 [3, 1, 1, 4, 1, 4] True\n011110 [3, 1, 1, 4, 1, 3] True\n011111 [3, 1, 1, 4, 1, 4] True\n100000 [4, 1, 1, 3, 1, 3] True\nAccuracy of the network on the 10000 test images: 29.26 %\nAccuracy of the network on the 10000 test images: 32.188 %\nAccuracy of the network on the 10000 test images: 32.263999999999996 %\nAverage score: 0.31237333333333334\n100001 [4, 1, 1, 3, 1, 4] True\nAccuracy of the network on the 10000 test images: 33.836 %\nAccuracy of the network on the 10000 test images: 34.4 %\nAccuracy of the network on the 10000 test images: 33.152 %\nAverage score: 0.33796\n100010 [4, 1, 1, 3, 1, 3] True\n100011 [4, 1, 1, 3, 1, 4] True\n100100 [4, 1, 1, 4, 1, 3] True\nAccuracy of the network on the 10000 test images: 31.884 %\nAccuracy of the network on the 10000 test images: 34.036 %\nAccuracy of the network on the 10000 test images: 35.844 %\nAverage score: 0.33921333333333337\n100101 [4, 1, 1, 4, 1, 4] True\nAccuracy of the network on the 10000 test images: 23.363999999999997 %\nAccuracy of the network on the 10000 test images: 23.496 %\nAccuracy of the network on the 10000 test images: 23.176 %\nAverage score: 0.23345333333333332\n100110 [4, 1, 1, 4, 1, 3] True\n100111 [4, 1, 1, 4, 1, 4] True\n101000 [4, 1, 1, 3, 1, 3] True\n101001 [4, 1, 1, 3, 1, 4] True\n101010 [4, 1, 1, 3, 1, 3] True\n101011 [4, 1, 1, 3, 1, 4] True\n101100 [4, 1, 1, 4, 1, 3] True\n101101 [4, 1, 1, 4, 1, 4] True\n101110 [4, 1, 1, 4, 1, 3] True\n101111 [4, 1, 1, 4, 1, 4] True\n110000 [4, 1, 1, 3, 1, 3] True\n110001 [4, 1, 1, 3, 1, 4] True\n110010 [4, 1, 1, 3, 1, 3] True\n110011 [4, 1, 1, 3, 1, 4] True\n110100 [4, 1, 1, 4, 1, 3] True\n110101 [4, 1, 1, 4, 1, 4] True\n110110 [4, 1, 1, 4, 1, 3] True\n110111 [4, 1, 1, 4, 1, 4] True\n111000 [4, 1, 1, 3, 1, 3] True\n111001 [4, 1, 1, 3, 1, 4] True\n111010 [4, 1, 1, 3, 1, 3] True\n111011 [4, 1, 1, 3, 1, 4] True\n111100 [4, 1, 1, 4, 1, 3] True\n111101 [4, 1, 1, 4, 1, 4] True\n111110 [4, 1, 1, 4, 1, 3] True\n111111 [4, 1, 1, 4, 1, 4] True\n2 [5, 1, 1, 7, 1, 7]\nAccuracy of the network on the 10000 test images: 43.891999999999996 %\nAccuracy of the network on the 10000 test images: 42.348 %\nAccuracy of the network on the 10000 test images: 41.836 %\nAverage score: 0.42692\n000000 [5, 1, 1, 7, 1, 7] True\n000001 [5, 1, 1, 7, 1, 8] True\nAccuracy of the network on the 10000 test images: 35.372 %\nAccuracy of the network on the 10000 test images: 39.224 %\nAccuracy of the network on the 10000 test images: 35.484 %\nAverage score: 0.36693333333333333\n000010 [5, 1, 1, 7, 1, 7] True\n000011 [5, 1, 1, 7, 1, 8] True\n000100 [5, 1, 1, 8, 1, 7] True\nAccuracy of the network on the 10000 test images: 37.424 %\nAccuracy of the network on the 10000 test images: 37.54 %\nAccuracy of the network on the 10000 test images: 36.204 %\nAverage score: 0.37056\n000101 [5, 1, 1, 8, 1, 8] True\nAccuracy of the network on the 10000 test images: 32.504 %\nAccuracy of the network on the 10000 test images: 33.391999999999996 %\nAccuracy of the network on the 10000 test images: 33.788000000000004 %\nAverage score: 0.33227999999999996\n000110 [5, 1, 1, 8, 1, 7] True\n000111 [5, 1, 1, 8, 1, 8] True\n001000 [5, 1, 1, 7, 1, 7] True\n001001 [5, 1, 1, 7, 1, 8] True\n001010 [5, 1, 1, 7, 1, 7] True\n001011 [5, 1, 1, 7, 1, 8] True\n001100 [5, 1, 1, 8, 1, 7] True\n001101 [5, 1, 1, 8, 1, 8] True\n001110 [5, 1, 1, 8, 1, 7] True\n001111 [5, 1, 1, 8, 1, 8] True\n010000 [5, 1, 1, 7, 1, 7] True\n010001 [5, 1, 1, 7, 1, 8] True\n010010 [5, 1, 1, 7, 1, 7] True\n010011 [5, 1, 1, 7, 1, 8] True\n010100 [5, 1, 1, 8, 1, 7] True\n010101 [5, 1, 1, 8, 1, 8] True\n010110 [5, 1, 1, 8, 1, 7] True\n010111 [5, 1, 1, 8, 1, 8] True\n011000 [5, 1, 1, 7, 1, 7] True\n011001 [5, 1, 1, 7, 1, 8] True\n011010 [5, 1, 1, 7, 1, 7] True\n011011 [5, 1, 1, 7, 1, 8] True\n011100 [5, 1, 1, 8, 1, 7] True\n011101 [5, 1, 1, 8, 1, 8] True\n011110 [5, 1, 1, 8, 1, 7] True\n011111 [5, 1, 1, 8, 1, 8] True\n100000 [6, 1, 1, 7, 1, 7] True\nAccuracy of the network on the 10000 test images: 40.444 %\nAccuracy of the network on the 10000 test images: 41.004000000000005 %\nAccuracy of the network on the 10000 test images: 35.196 %\nAverage score: 0.3888133333333334\n100001 [6, 1, 1, 7, 1, 8] True\nAccuracy of the network on the 10000 test images: 30.064 %\nAccuracy of the network on the 10000 test images: 35.556 %\nAccuracy of the network on the 10000 test images: 29.976000000000003 %\nAverage score: 0.31865333333333334\n100010 [6, 1, 1, 7, 1, 7] True\n100011 [6, 1, 1, 7, 1, 8] True\n100100 [6, 1, 1, 8, 1, 7] True\nAccuracy of the network on the 10000 test images: 30.259999999999998 %\nAccuracy of the network on the 10000 test images: 31.163999999999998 %\nAccuracy of the network on the 10000 test images: 28.811999999999998 %\nAverage score: 0.3007866666666666\n100101 [6, 1, 1, 8, 1, 8] True\nAccuracy of the network on the 10000 test images: 27.855999999999998 %\nAccuracy of the network on the 10000 test images: 24.936 %\nAccuracy of the network on the 10000 test images: 29.612 %\nAverage score: 0.27468\n100110 [6, 1, 1, 8, 1, 7] True\n100111 [6, 1, 1, 8, 1, 8] True\n101000 [6, 1, 1, 7, 1, 7] True\n101001 [6, 1, 1, 7, 1, 8] True\n101010 [6, 1, 1, 7, 1, 7] True\n101011 [6, 1, 1, 7, 1, 8] True\n101100 [6, 1, 1, 8, 1, 7] True\n101101 [6, 1, 1, 8, 1, 8] True\n101110 [6, 1, 1, 8, 1, 7] True\n101111 [6, 1, 1, 8, 1, 8] True\n110000 [6, 1, 1, 7, 1, 7] True\n110001 [6, 1, 1, 7, 1, 8] True\n110010 [6, 1, 1, 7, 1, 7] True\n110011 [6, 1, 1, 7, 1, 8] True\n110100 [6, 1, 1, 8, 1, 7] True\n110101 [6, 1, 1, 8, 1, 8] True\n110110 [6, 1, 1, 8, 1, 7] True\n110111 [6, 1, 1, 8, 1, 8] True\n111000 [6, 1, 1, 7, 1, 7] True\n111001 [6, 1, 1, 7, 1, 8] True\n111010 [6, 1, 1, 7, 1, 7] True\n111011 [6, 1, 1, 7, 1, 8] True\n111100 [6, 1, 1, 8, 1, 7] True\n111101 [6, 1, 1, 8, 1, 8] True\n111110 [6, 1, 1, 8, 1, 7] True\n111111 [6, 1, 1, 8, 1, 8] True\n[5, 1, 1, 7, 1, 7]\n","output_type":"stream"}]}]}